{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplabv3plus.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KNSInGfbCBKS"
      ],
      "authorship_tag": "ABX9TyOf21kg0DNFo26GFtjeyDhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotaxtech/Deeplabv3plus/blob/main/deeplabv3plus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# セットアップ"
      ],
      "metadata": {
        "id": "KNSInGfbCBKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、Tensorflowのインストール\n",
        "\n",
        "Versionが1.15.2であることを確認した後、GPU版のTensorflowもインストールします。\n",
        "\n",
        "※下のように警告文（Warning）が出ることがありますが、スルーで大丈夫です。\n",
        "\n",
        "```\n",
        "WARNING: The following packages were previously imported in this runtime:\n",
        "\n",
        "  [gast,tensorflow,tensorflow_core]\n",
        "\n",
        "You must restart the runtime in order to use newly installed versions.\n",
        "```"
      ],
      "metadata": {
        "id": "DQGzBJWjDo83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRpFy4oKB5cE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip3 install  tensorflow-gpu==1.15.2\n",
        "!pip install tensorflow-determinism\n",
        "!pip install tf_slim\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、Githubからモデルをインストールしていきます。\n",
        "\n",
        "（Tensorflowの公式リポジトリに専用のモデルがあるようです。）\n",
        "\n",
        "model_test.pyを実行し、上手くいけば\"OK\"と出力されます。"
      ],
      "metadata": {
        "id": "DO2cAk3BCN9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/drive/My Drive/\n",
        "mkdir tensorflow\n",
        "cd tensorflow\n",
        "git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "cd /content/drive/My Drive/tensorflow/models/research/\n",
        "researchpath = %pwd\n",
        "env PYTHONPATH = $researchpath:$researchpath/slim\n",
        "#export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
        "python deeplab/model_test.py"
      ],
      "metadata": {
        "id": "pbv78cNKClmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 教師データの変換"
      ],
      "metadata": {
        "id": "rVNsbheQDdzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "教師データをグレースケールおよびTFrecordに変換します．まず/tensorflow/models/research/deeplab/datasetsに\"pascal_voc_seg\"という名前でディレクトリを作成します．(以下のコードを実行すると勝手に作成されます．)"
      ],
      "metadata": {
        "id": "cXCkHfE3D0Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CURRENT_DIR = %pwd\n",
        "WORK_DIR = \"./pascal_voc_seg\"\n",
        "!mkdir -v $WORK_DIR\n",
        "%cd $WORK_DIR"
      ],
      "metadata": {
        "id": "ly-lRTtTEAK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "さらにpascal_voc_segディレクトリ直下に各ディレクトリを作成します．(これも以下のコードを実行すると勝手に作成されます．)"
      ],
      "metadata": {
        "id": "mjly_pOgGnY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $CURRENT_DIR\n",
        "\n",
        "PASCAL_ROOT = WORK_DIR + \"/VOCdevkit/VOC2012\"\n",
        "\n",
        "SEG_FOLDER = PASCAL_ROOT + \"/SegmentationClass\"\n",
        "SEMANTIC_SEG_FOLDER = PASCAL_ROOT + \"/SegmentationClassRaw\"\n",
        "\n",
        "IMAGE_FOLDER = PASCAL_ROOT + \"/JPEGImages\"\n",
        "LIST_FOLDER = PASCAL_ROOT + \"/ImageSets/Segmentation\"\n",
        "\n",
        "!mkdir -p -v $PASCAL_ROOT $LIST_FOLDER\n",
        "!mkdir -v $SEG_FOLDER  $SEMANTIC_SEG_FOLDER $IMAGE_FOLDER"
      ],
      "metadata": {
        "id": "GCp15KulGFkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "作成されたSegmentationディレクトリ内にtrain.txt，val.txtを作成します．\n",
        "\n",
        "（⬆これは、事前に作成する訓練データと検証データのファイル名です．）\n",
        "\n",
        "学習データと教師データの名前は同じにします．\n",
        "\n",
        "このとき，学習データをjpg 教師データをpngの拡張子にします．（そういう仕様？）\n",
        "\n",
        "ex)学習データ：001.jpg トレーニングデータ：001.png\n",
        "\n",
        "以下のようなフォルダ構成になっているか確認してください。\n",
        "\n",
        "```\n",
        "./pascal_voc_seg\n",
        "  └ VOCdevkit\n",
        "    └ VOC2012\n",
        "        ├ ImageSets\n",
        "        │  └ Segmentation\n",
        "        │     ├ train.txt(訓練データのリスト)\n",
        "        │     └ val.txt(検証データのリスト)\n",
        "        ├ SegmentationClass(教師データ)\n",
        "        ├ SegmentationClassRaw(教師データのGrayScale版：この時点では空)\n",
        "        └ JPEGImages(元データ)\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "Xc-KbbgfFLWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に/tensorflow/models/research/deeplab/datasets/data_generator.py の\n",
        "\n",
        "82～91行目を自分のデータセットに合わせて書き換えます。\n",
        "\n",
        " [コチラ](https://qiita.com/mucchyo/items/d21993abee5e6e44efad#%E5%AD%A6%E7%BF%92%E6%A4%9C%E8%A8%BC%E3%83%87%E3%83%BC%E3%82%BF%E8%A8%AD%E5%AE%9A%E3%81%AE%E5%A4%89%E6%9B%B4)を参考にしました。\n",
        "\n",
        "※注意\n",
        "- train, valはそれぞれ訓練データ枚数，検証データ枚数\n",
        "- trainvalは...train + valの値を設定\n",
        "- train_augは、画像データの拡張枚数。そのままでいい（らしい…）\n",
        "- 今回は転移学習(21クラス→3クラス)を実施するので、num_classesは21のままでいい（らしい…）\n",
        "\n",
        "```\n",
        "_PASCAL_VOC_SEG_INFORMATION = DatasetDescriptor(\n",
        "    splits_to_sizes={\n",
        "        'train': 600,\n",
        "        'train_aug': 10582,\n",
        "        'trainval': 975,\n",
        "        'val': 375,\n",
        "    },\n",
        "    num_classes=21,\n",
        "    ignore_label=255,\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "-CaDCyODHzp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "現段階で教師データはインデックスカラー形式になっているので、グレースケールに変換する必要があります。（…あるのか？）\n",
        "\n",
        "以下のコードを実行すると、SegmentationClassRawフォルダにグレースケール画像が出力されます。\n"
      ],
      "metadata": {
        "id": "QrLSriBCIISe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Removing the color map in ground truth annotations...\")\n",
        "\n",
        "%time !python remove_gt_colormap.py \\\n",
        "  --original_gt_folder=$SEG_FOLDER \\\n",
        "  --output_dir=$SEMANTIC_SEG_FOLDER"
      ],
      "metadata": {
        "id": "sjl5u4CUHy7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データセットの事前準備できたので、次はTensorFlow用の形式である「TFRecord」に変換していきます。\n",
        "\n",
        "従来よりもデータサイズが削減できて、学習コストを抑えることができるそう…\n",
        "\n",
        "以下のコードを実行したらpascal_voc_segフォルダに作成されているtfrecordフォルダを確認してください。\n",
        "\n",
        "うまく動作していると以下のファイルが出力されています。\n",
        "\n",
        "- train-00000-of-00004.tfrecord  \n",
        "- train-00001-of-00004.tfrecord  \n",
        "- train-00002-of-00004.tfrecord\n",
        "- train-00003-of-00004.tfrecord\n",
        "- val-00000-of-00004.tfrecord\n",
        "- val-00001-of-00004.tfrecord\n",
        "- val-00002-of-00004.tfrecord\n",
        "- val-00003-of-00004.tfrecord\n"
      ],
      "metadata": {
        "id": "Nu1NJaK5IOKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OUTPUT_DIR = WORK_DIR + \"/tfrecord\"\n",
        "OUTPUT_DIR = \"./pascal_voc_seg/tfrecord\"\n",
        "!mkdir -p $OUTPUT_DIR\n",
        "\n",
        "#IMAGE_FOLDER = PASCAL_ROOT + \"/JPEGImages\"\n",
        "#LIST_FOLDER = PASCAL_ROOT + \"/ImageSets/Segmentation\"\n",
        "\n",
        "print(\"Converting PASCAL VOC 2012 dataset...\")\n",
        "\n",
        "%time !python build_voc2012_data.py \\\n",
        "  --image_folder=$IMAGE_FOLDER \\\n",
        "  --semantic_segmentation_folder=$SEMANTIC_SEG_FOLDER \\\n",
        "  --list_folder=$LIST_FOLDER \\\n",
        "  --image_format=\"jpg\" \\\n",
        "  --output_dir=$OUTPUT_DIR"
      ],
      "metadata": {
        "id": "w9L99diSIMAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ディレクトリの作成"
      ],
      "metadata": {
        "id": "SIEyx0MKIhkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ソースコード上で使用するディレクトリを設定する．(以下のコードを実行すると勝手にディレクトリが作成される．)\n",
        "\n",
        "|フォルダ名|意味|\n",
        "|---|---|\n",
        "|INIT_FOLDER|学習済みの結合荷重|\n",
        "|TRAIN_LOGDIR|学習結果(訓練)の保存先|\n",
        "|EVAL_LOGDIR|学習結果(検証)の保存先|\n",
        "|VIS_LOGDIR|可視化画像(検証)の保存先|\n",
        "|EXPORT_DIR|学習したモデルの保存先|\n",
        "|PASCAL_DATASET|TFRecord化したデータセット|"
      ],
      "metadata": {
        "id": "4zIz0HAhIxhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CURRENT_DIR = %pwd\n",
        "DATASET_DIR = \"datasets\"\n",
        "\n",
        "PASCAL_FOLDER = \"/pascal_voc_seg\"\n",
        "EXP_FOLDER = \"/exp/train_on_trainval_set\"\n",
        "INIT_FOLDER = DATASET_DIR + PASCAL_FOLDER + \"/init_models\"\n",
        "TRAIN_LOGDIR = DATASET_DIR + PASCAL_FOLDER + EXP_FOLDER + \"/train\"\n",
        "EVAL_LOGDIR = DATASET_DIR + PASCAL_FOLDER + EXP_FOLDER + \"/eval\"\n",
        "VIS_LOGDIR = DATASET_DIR + PASCAL_FOLDER + EXP_FOLDER + \"/vis\"\n",
        "EXPORT_DIR = DATASET_DIR + PASCAL_FOLDER + EXP_FOLDER + \"/export\"\n",
        "\n",
        "PASCAL_DATASET = DATASET_DIR + PASCAL_FOLDER + \"/tfrecord\"\n",
        "\n",
        "!mkdir -p -v $INIT_FOLDER $TRAIN_LOGDIR $EVAL_LOGDIR $VIS_LOGDIR $EXPORT_DIR"
      ],
      "metadata": {
        "id": "gS1-V-KGIWvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習済み結合荷重をダウンロードする．(1回ダウンロードしたら2周目以降は実行しなくて大丈夫．)"
      ],
      "metadata": {
        "id": "xlqMBL_YI6te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF_INIT_ROOT = \"http://download.tensorflow.org/models\"\n",
        "TF_INIT_CKPT = \"deeplabv3_pascal_train_aug_2018_01_04.tar.gz\"\n",
        "%cd $INIT_FOLDER\n",
        "!wget -nd -c $TF_INIT_ROOT/$TF_INIT_CKPT\n",
        "!tar -xf $TF_INIT_CKPT\n",
        "\n",
        "TF_INIT_ROOT = \"http://download.tensorflow.org/models\"\n",
        "TF_INIT_CKPT = \"deeplabv3_xception_2018_01_04.tar.gz\"\n",
        "%cd $INIT_FOLDER\n",
        "!wget -nd -c $TF_INIT_ROOT/$TF_INIT_CKPT\n",
        "!tar -xf $TF_INIT_CKPT\n",
        "\n",
        "TF_INIT_ROOT = \"http://download.tensorflow.org/models\"\n",
        "TF_INIT_CKPT = \"xception_65_coco_pretrained_2018_10_02.tar.gz\"\n",
        "%cd $INIT_FOLDER\n",
        "!wget -nd -c $TF_INIT_ROOT/$TF_INIT_CKPT\n",
        "!tar -xf $TF_INIT_CKPT\n",
        "%cd $CURRENT_DIR"
      ],
      "metadata": {
        "id": "veo4sFmfI-zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "指定したディレクトリに3つの学習済み結合荷重がダウンロードされていることを確認する．"
      ],
      "metadata": {
        "id": "xal3aVfwJ_Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $INIT_FOLDER\n",
        "'''\n",
        "出力結果…\n",
        "　deeplabv3_pascal_train_aug\n",
        "　deeplabv3_pascal_train_aug_2018_01_04.tar.gz\n",
        "　deeplabv3_xception_2018_01_04.tar.gz\n",
        "　xception\n",
        "　xception_65_coco_pretrained\n",
        "　xception_65_coco_pretrained_2018_10_02.tar.gz\n",
        "'''"
      ],
      "metadata": {
        "id": "GzikA65DJ94J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習"
      ],
      "metadata": {
        "id": "COEDQt4waIIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここから学習です．\n",
        "models/research/deeplab/train.pyの266行目を書き換えると学習時の重みが変更できます．\n",
        "\n",
        "\n",
        "```\n",
        "  for output, num_classes in six.iteritems(outputs_to_num_classes):\n",
        "    train_utils.add_softmax_cross_entropy_loss_for_each_scale(\n",
        "        outputs_to_scales_to_logits[output],\n",
        "        samples[common.LABEL],\n",
        "        num_classes,\n",
        "        ignore_label,\n",
        "        #loss_weight=model_options.label_weights,\n",
        "        loss_weight=[0.002, 2.63, 2.56],←ココ\n",
        "        upsample_logits=FLAGS.upsample_logits,\n",
        "        hard_example_mining_step=FLAGS.hard_example_mining_step,\n",
        "        top_k_percent_pixels=FLAGS.top_k_percent_pixels,\n",
        "        scope=output)\n",
        "```"
      ],
      "metadata": {
        "id": "AkXGLXuRKlIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習回数を指定(デフォルトでは30000 iterations)\n",
        "NUM_ITERATIONS=30000"
      ],
      "metadata": {
        "id": "qC0h8ef_KymH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "主に変更したのは，以下の4つ．\n",
        "- training_number_of_step：学習回数(10000くらいでも収束する)\n",
        "- train_crop_size：データセットの解像度(257,257 or 513,513が妥当)\n",
        "- tf_initial_checkpoint：学習済み結合荷重(ダウンロードした3つから適宜選定)\n",
        "- train_batch_size：ミニバッチサイズ(Colab環境だと2で限界…？)"
      ],
      "metadata": {
        "id": "Z6C8R1BYafmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --logtostderr \\\n",
        "  --training_number_of_steps=$NUM_ITERATIONS \\\n",
        "  --train_split=\"train\" \\\n",
        "  --model_variant=\"xception_65\" \\\n",
        "  --atrous_rates=6 \\\n",
        "  --atrous_rates=12 \\\n",
        "  --atrous_rates=18 \\\n",
        "  --output_stride=16 \\\n",
        "  --decoder_output_stride=4 \\\n",
        "  --train_crop_size=\"257,257\" \\\n",
        "  --dataset=\"pascal_voc_seg\" \\\n",
        "  --tf_initial_checkpoint=$INIT_FOLDER/xception_65_coco_pretrained/x65-b2u1s2p-d48-2-3x256-sc-cr300k_init.ckpt \\\n",
        "  --train_logdir=$TRAIN_LOGDIR \\\n",
        "  --fine_tune_batch_norm=false \\\n",
        "  --dataset_dir=$PASCAL_DATASET \\\n",
        "  --train_batch_size=2 \\\n",
        "  --initialize_last_layer=false \\\n",
        "  --last_layers_contain_logits_only=true \\\n",
        "  --base_learning_rate=0.001 \\\n",
        "  --learning_rate_decay_factor=0.3 \\\n",
        "  --learning_rate_decay_step=2000"
      ],
      "metadata": {
        "id": "OHRAAhawLL1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 結果"
      ],
      "metadata": {
        "id": "n2_OBzZLcLE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習結果に対しmIoUを算出します．"
      ],
      "metadata": {
        "id": "vlwjoV22L7_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time !python eval.py \\\n",
        " --logtostderr \\\n",
        " --eval_split=\"val\" \\\n",
        " --model_variant=\"xception_65\" \\\n",
        " --atrous_rates=6 \\\n",
        " --atrous_rates=12 \\\n",
        " --atrous_rates=18 \\\n",
        " --output_stride=16 \\\n",
        " --decoder_output_stride=4 \\\n",
        " --eval_crop_size=\"257,257\" \\\n",
        " --checkpoint_dir=$TRAIN_LOGDIR \\\n",
        " --eval_logdir=$EVAL_LOGDIR \\\n",
        " --dataset_dir=$PASCAL_DATASET \\\n",
        " --max_number_of_evaluations=1"
      ],
      "metadata": {
        "id": "N13oZORQL68_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習結果に対し検証データの出力結果を可視化します．"
      ],
      "metadata": {
        "id": "zFqACXXrMIuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time !python vis.py \\\n",
        " --logtostderr \\\n",
        " --vis_split=\"val\" \\\n",
        " --model_variant=\"xception_65\" \\\n",
        " --atrous_rates=6 \\\n",
        " --atrous_rates=12 \\\n",
        " --atrous_rates=18 \\\n",
        " --output_stride=16 \\\n",
        " --decoder_output_stride=4 \\\n",
        " --vis_crop_size=\"257,257\" \\\n",
        " --checkpoint_dir=$TRAIN_LOGDIR \\\n",
        " --vis_logdir=$VIS_LOGDIR \\\n",
        " --dataset_dir=$PASCAL_DATASET \\\n",
        " --max_number_of_iterations=1"
      ],
      "metadata": {
        "id": "gu5wLgdKMHUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルの保存"
      ],
      "metadata": {
        "id": "Aa2F67t6cTdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習モデルを保存します．"
      ],
      "metadata": {
        "id": "H5-dM8zMMejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CKPT_PATH = f\"{TRAIN_LOGDIR}/model.ckpt-{str(NUM_ITERATIONS)}\"\n",
        "EXPORT_PATH = f\"{EXPORT_DIR}/checkpoint_{str(NUM_ITERATIONS)}.pb\"\n",
        "\n",
        "%time !python export_model.py \\\n",
        "  --logtostderr \\\n",
        "  --checkpoint_path=$CKPT_PATH \\\n",
        "  --export_path=$EXPORT_PATH \\\n",
        "  --model_variant=\"xceptions_65\" \\\n",
        "  --atrous_rates=6 \\\n",
        "  --atrous_rates=12 \\\n",
        "  --atrous_rates=18 \\\n",
        "  --output_stride=16 \\\n",
        "  --decoder_output_stride=4 \\\n",
        "  --num_classes=21 \\\n",
        "  --crop_size=257 \\\n",
        "  --crop_size=257 \\\n",
        "  --inference_scales=1.0"
      ],
      "metadata": {
        "id": "pDkAgjBdMhge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}